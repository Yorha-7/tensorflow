{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f90b6d-6db9-412e-a6d4-65db3f09b128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 10:49:44.943478: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-23 10:49:44.957695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734950984.968971    1162 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734950984.972252    1162 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-23 10:49:44.986264: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      "X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734950989.928527    1162 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m2048\u001b[0m)   │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,028\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,113,284</span> (91.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,113,284\u001b[0m (91.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">525,572</span> (2.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m525,572\u001b[0m (2.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734951019.170619    1323 service.cc:148] XLA service 0x7f5a54013a90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734951019.172039    1323 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-12-23 10:50:19.391013: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1734951020.164503    1323 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-12-23 10:50:22.049878: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5630_0', 112 bytes spill stores, 224 bytes spill loads\n",
      "\n",
      "2024-12-23 10:50:22.603646: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5630', 220 bytes spill stores, 576 bytes spill loads\n",
      "\n",
      "2024-12-23 10:50:26.697500: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,64,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,500,500]{3,2,1,0}, f32[64,3,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7 stride=2x2 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-12-23 10:50:27.332960: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.635229097s\n",
      "Trying algorithm eng0{} for conv (f32[32,64,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,500,500]{3,2,1,0}, f32[64,3,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7 stride=2x2 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "I0000 00:00:1734951038.732850    1323 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.5240 - loss: 56.1270   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 10:50:55.652579: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1709_0', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-12-23 10:50:56.102676: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1709', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-12-23 10:50:56.452661: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1709', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14s/step - accuracy: 0.4930 - loss: 67.0861 - val_accuracy: 0.2500 - val_loss: 0.3893\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - accuracy: 0.2398 - loss: 0.3624 - val_accuracy: 0.2500 - val_loss: 0.2981\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.2164 - loss: 0.2686 - val_accuracy: 0.2500 - val_loss: 0.1801\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - accuracy: 0.2594 - loss: 0.1518 - val_accuracy: 0.2500 - val_loss: 0.0853\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - accuracy: 0.2633 - loss: 0.0718 - val_accuracy: 0.2500 - val_loss: 0.0400\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - accuracy: 0.2516 - loss: 0.0376 - val_accuracy: 0.2500 - val_loss: 0.0244\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - accuracy: 0.3961 - loss: 0.0246 - val_accuracy: 0.7500 - val_loss: 0.0198\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - accuracy: 0.7836 - loss: 0.0199 - val_accuracy: 0.7500 - val_loss: 0.0185\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.7563 - loss: 0.0201 - val_accuracy: 0.7500 - val_loss: 0.0177\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - accuracy: 0.7953 - loss: 0.0201 - val_accuracy: 0.7500 - val_loss: 0.0180\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - accuracy: 0.7641 - loss: 0.0189 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375ms/step - accuracy: 0.7484 - loss: 0.0186 - val_accuracy: 0.7500 - val_loss: 0.0181\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - accuracy: 0.7133 - loss: 0.0197 - val_accuracy: 0.7500 - val_loss: 0.0177\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - accuracy: 0.7836 - loss: 0.0200 - val_accuracy: 0.7500 - val_loss: 0.0177\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.7641 - loss: 0.0189 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - accuracy: 0.7914 - loss: 0.0196 - val_accuracy: 0.7500 - val_loss: 0.0186\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - accuracy: 0.7563 - loss: 0.0196 - val_accuracy: 0.7500 - val_loss: 0.0177\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - accuracy: 0.7563 - loss: 0.0192 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - accuracy: 0.7523 - loss: 0.0206 - val_accuracy: 0.7500 - val_loss: 0.0178\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step - accuracy: 0.7719 - loss: 0.0189 - val_accuracy: 0.7500 - val_loss: 0.0188\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403ms/step - accuracy: 0.7953 - loss: 0.0194 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.7719 - loss: 0.0201 - val_accuracy: 0.7500 - val_loss: 0.0183\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - accuracy: 0.7836 - loss: 0.0204 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - accuracy: 0.7563 - loss: 0.0197 - val_accuracy: 0.7500 - val_loss: 0.0181\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - accuracy: 0.7758 - loss: 0.0185 - val_accuracy: 0.7500 - val_loss: 0.0179\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - accuracy: 0.7641 - loss: 0.0213 - val_accuracy: 0.7500 - val_loss: 0.0178\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - accuracy: 0.7836 - loss: 0.0195 - val_accuracy: 0.7500 - val_loss: 0.0186\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - accuracy: 0.7641 - loss: 0.0202 - val_accuracy: 0.7500 - val_loss: 0.0178\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - accuracy: 0.7523 - loss: 0.0178 - val_accuracy: 0.7500 - val_loss: 0.0198\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - accuracy: 0.7680 - loss: 0.0198 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - accuracy: 0.7914 - loss: 0.0214 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - accuracy: 0.7445 - loss: 0.0203 - val_accuracy: 0.7500 - val_loss: 0.0177\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - accuracy: 0.7836 - loss: 0.0201 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - accuracy: 0.7602 - loss: 0.0189 - val_accuracy: 0.7500 - val_loss: 0.0178\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - accuracy: 0.7758 - loss: 0.0196 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.7797 - loss: 0.0205 - val_accuracy: 0.7500 - val_loss: 0.0173\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - accuracy: 0.7797 - loss: 0.0191 - val_accuracy: 0.7500 - val_loss: 0.0182\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.7875 - loss: 0.0187 - val_accuracy: 0.7500 - val_loss: 0.0180\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - accuracy: 0.7602 - loss: 0.0203 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - accuracy: 0.7680 - loss: 0.0195 - val_accuracy: 0.7500 - val_loss: 0.0177\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - accuracy: 0.7563 - loss: 0.0198 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - accuracy: 0.7719 - loss: 0.0192 - val_accuracy: 0.7500 - val_loss: 0.0179\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.7914 - loss: 0.0192 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - accuracy: 0.7602 - loss: 0.0204 - val_accuracy: 0.7500 - val_loss: 0.0182\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - accuracy: 0.7328 - loss: 0.0208 - val_accuracy: 0.7500 - val_loss: 0.0181\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - accuracy: 0.7523 - loss: 0.0193 - val_accuracy: 0.7500 - val_loss: 0.0182\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376ms/step - accuracy: 0.7602 - loss: 0.0199 - val_accuracy: 0.7500 - val_loss: 0.0177\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375ms/step - accuracy: 0.7602 - loss: 0.0213 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - accuracy: 0.7602 - loss: 0.0201 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - accuracy: 0.7523 - loss: 0.0196 - val_accuracy: 0.7500 - val_loss: 0.0185\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - accuracy: 0.7719 - loss: 0.0202 - val_accuracy: 0.7500 - val_loss: 0.0182\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - accuracy: 0.8070 - loss: 0.0199 - val_accuracy: 0.7500 - val_loss: 0.0177\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - accuracy: 0.7758 - loss: 0.0190 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - accuracy: 0.7641 - loss: 0.0179 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - accuracy: 0.7563 - loss: 0.0189 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - accuracy: 0.7563 - loss: 0.0208 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376ms/step - accuracy: 0.7602 - loss: 0.0202 - val_accuracy: 0.7500 - val_loss: 0.0184\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - accuracy: 0.7602 - loss: 0.0202 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - accuracy: 0.7719 - loss: 0.0190 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - accuracy: 0.7719 - loss: 0.0198 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - accuracy: 0.7797 - loss: 0.0186 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.7602 - loss: 0.0190 - val_accuracy: 0.7500 - val_loss: 0.0206\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.7563 - loss: 0.0202 - val_accuracy: 0.7500 - val_loss: 0.0181\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372ms/step - accuracy: 0.7758 - loss: 0.0194 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - accuracy: 0.7563 - loss: 0.0178 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.7797 - loss: 0.0196 - val_accuracy: 0.7500 - val_loss: 0.0173\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - accuracy: 0.7719 - loss: 0.0215 - val_accuracy: 0.7500 - val_loss: 0.0180\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379ms/step - accuracy: 0.7797 - loss: 0.0193 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - accuracy: 0.7758 - loss: 0.0185 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - accuracy: 0.7875 - loss: 0.0199 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - accuracy: 0.7680 - loss: 0.0211 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - accuracy: 0.7680 - loss: 0.0191 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - accuracy: 0.7719 - loss: 0.0191 - val_accuracy: 0.7500 - val_loss: 0.0178\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - accuracy: 0.7289 - loss: 0.0193 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - accuracy: 0.7367 - loss: 0.0206 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - accuracy: 0.7602 - loss: 0.0200 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - accuracy: 0.7758 - loss: 0.0184 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - accuracy: 0.7563 - loss: 0.0205 - val_accuracy: 0.7500 - val_loss: 0.0181\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - accuracy: 0.7406 - loss: 0.0212 - val_accuracy: 0.7500 - val_loss: 0.0176\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - accuracy: 0.7406 - loss: 0.0202 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.7367 - loss: 0.0200 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.7563 - loss: 0.0203 - val_accuracy: 0.7500 - val_loss: 0.0178\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step - accuracy: 0.7797 - loss: 0.0187 - val_accuracy: 0.7500 - val_loss: 0.0177\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477ms/step - accuracy: 0.7758 - loss: 0.0200 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 387ms/step - accuracy: 0.7680 - loss: 0.0190 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step - accuracy: 0.7641 - loss: 0.0203 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - accuracy: 0.7484 - loss: 0.0213 - val_accuracy: 0.7500 - val_loss: 0.0183\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - accuracy: 0.7719 - loss: 0.0187 - val_accuracy: 0.7500 - val_loss: 0.0184\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - accuracy: 0.7445 - loss: 0.0199 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - accuracy: 0.7602 - loss: 0.0203 - val_accuracy: 0.7500 - val_loss: 0.0184\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - accuracy: 0.7680 - loss: 0.0203 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - accuracy: 0.7836 - loss: 0.0201 - val_accuracy: 0.7500 - val_loss: 0.0174\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - accuracy: 0.7367 - loss: 0.0191 - val_accuracy: 0.7500 - val_loss: 0.0179\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.7289 - loss: 0.0207 - val_accuracy: 0.7500 - val_loss: 0.0178\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - accuracy: 0.7484 - loss: 0.0182 - val_accuracy: 0.7500 - val_loss: 0.0184\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - accuracy: 0.7758 - loss: 0.0193 - val_accuracy: 0.7500 - val_loss: 0.0178\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394ms/step - accuracy: 0.7602 - loss: 0.0196 - val_accuracy: 0.7500 - val_loss: 0.0178\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - accuracy: 0.7719 - loss: 0.0205 - val_accuracy: 0.7500 - val_loss: 0.0182\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - accuracy: 0.7641 - loss: 0.0202 - val_accuracy: 0.7500 - val_loss: 0.0175\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360ms/step - accuracy: 0.7719 - loss: 0.0186 - val_accuracy: 0.7500 - val_loss: 0.0176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "import matplotlib.pyplot as mlt\n",
    "\n",
    "\n",
    "Y = []\n",
    "X = []\n",
    "IMGSIZE = 500\n",
    "\n",
    "def parse_xml():\n",
    "    xml_file = 'TrainingImg'\n",
    "    for path in os.listdir(xml_file):\n",
    "        category = os.path.join(xml_file, path)\n",
    "        print(path)\n",
    "        if path == 'Y':\n",
    "            for y in os.listdir(category):\n",
    "                try:\n",
    "                    #print(y)\n",
    "                    tree = ET.parse(os.path.join(category, y))\n",
    "                    root = tree.getroot()\n",
    "                    size = root.find('size')\n",
    "                    width = int(size.find('width').text)\n",
    "                    height = int(size.find('height').text)\n",
    "                    for obj in root.findall('object'):\n",
    "                        bbox = obj.find('bndbox')\n",
    "                        xmin = int(bbox.find('xmin').text)\n",
    "                        ymin = int(bbox.find('ymin').text)\n",
    "                        xmax = int(bbox.find('xmax').text)\n",
    "                        ymax = int(bbox.find('ymax').text)\n",
    "                        label = obj.find('name').text\n",
    "                        Y.append((xmin/width, ymin/height, xmax/width, ymax/height))\n",
    "                except Exception as e:\n",
    "                    pass  \n",
    "        if path == 'X':\n",
    "            for x in os.listdir(category):\n",
    "                try:\n",
    "                    #print(x)\n",
    "                    img_array = cv2.imread(os.path.join(category, x))\n",
    "                    img_array = cv2.resize(img_array, (IMGSIZE, IMGSIZE))\n",
    "                    img_array = np.array(img_array).reshape(IMGSIZE, IMGSIZE, 3)\n",
    "                    img_array=img_array/255.0\n",
    "                    X.append(img_array)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "parse_xml()\n",
    "#print(X)\n",
    "#print(Y)\n",
    "\n",
    "X_train = np.array(X)\n",
    "y_train = np.array(Y)\n",
    "\n",
    "def create_model(input_shape):\n",
    "    base_model = tf.keras.applications.ResNet50(input_shape=input_shape, include_top=False, weights='imagenet') \n",
    "    base_model.trainable = False\n",
    "    model = tf.keras.models.Sequential([\n",
    "        base_model,\n",
    "        #Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        #MaxPooling2D((2, 2)),\n",
    "        #Conv2D(32, (3, 3), activation='relu'),\n",
    "        #MaxPooling2D((2, 2)),\n",
    "        #Conv2D(64, (3, 3), activation='relu'),\n",
    "        #Flatten(),\n",
    "        #Dense(64, activation='relu'),\n",
    "        #Dense(32, activation='relu'),\n",
    "        #Dense(4,activation='linear')  \n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(num_classes)])\n",
    "    model.compile(optimizer='sgd', loss='mean_squared_error',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (IMGSIZE, IMGSIZE, 3)\n",
    "num_classes=4\n",
    "model = create_model(input_shape)\n",
    "model.summary()\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n",
    "model.save(\"testing.keras\")\n",
    "\n",
    "mlt.plot(history.history['accuracy'])\n",
    "mlt.plot(history.history['val_accuracy'])\n",
    "mlt.xlabel('loss')\n",
    "mlt.ylabel('accuracy')\n",
    "mlt.legend('train','test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
